James Steven Supančič IIIJames Steven Supančič III 
			 Computer Vision PhD Student at UC Irvine 
		
	


	
	
		
			
				

    
       
        Depth-based hand pose estimation  
       October
	  2015Posted
	  by James
       
      
	 
      
      
       Our  survey and evaluation of hand
	datasets and pose estimation methods  will be a poster at
	 ICCV 2015 .
	
	   
	      J. Supancic, G. Rogez, Y. Yang, D. Ramanan, J. Shotton. 
	       "Depth-based hand pose estimation: data, methods,
	      and challenges"   International Conference on
	      Computer Vision (ICCV), Santiago, Chile, December 2015.
	    
	    
	      Dataset and code  here 
	    
	
	
	
	   
	    Everyday Hands in Action  
	   October 
	      2015Posted
	      by James
	   
	  
	     
				      
	  
	   We present
	    our 
	    paper  on everyday hands in action.
	    
	       
		  G. Rogez, J. Supancic,
		  D. Ramanan.
		  "Understanding Everyday Hands in Action from
		  RGB-D Images"  International Conference on
		  Computer Vision  (ICCV), Santiago, Chile,
		  December 2015.
		
		
	      
	    
	
				  
				     
				      Pose in Egocentric Workspaces  
				      June
					  28th, 2015Posted
					  by James
				       
				      
					  We present our  paper  on hand pose recognition in egocentric workspaces.
					
					   
					  G. Rogez, J. Supancic,
					  D. Ramanan.
					  "First-Person Pose Recognition using Egocentric Workspaces" Computer Vision and Pattern Recognition (CVPR), Boston, MA, June 2015.
					    
					    
					    
					      The title was
					      formerly  "Egocentric
					      Pose Recognition in Four
					      Lines of Code". 
					    
					
				  
				  
				     
				      Hand Datasets and Methods  
				      
					  September
					  29th, 2015Posted
					  by James
				       
				      
					 
					
					    Our survey and evaluation of hand datasets and pose estimation methods is
					     on arXiv 
					  
					    J. Supancic, G. Rogez, Y. Yang, J. Shotton, D. Ramanan. "Depth-based hand pose estimation: methods, data, and challenges
" arXiv preprint arXiv:1504.06378 2015.
					  
					      Deep Convolutional
					      Network w/ Prior
					      Bottleneck source code  and a
					       pre-trained
					      network     Other methods,
					      specifically including Dual-Tree
					      accelerated 1-NN  
						 Modified
						  LibHand w/ Inverse-Kinematic Annotation 
						
					      
						 Dataset
						Link 
					      
					   Links to datasets mentioned in the paper: 
					  KTH ,
					  
					      LISA ,
					   
					      ASTAR ,
					  		
					      MSR ,
					   
					      NYU , 
					   
					      ICL , 
					   
					      FORTH , 
					   
					      Dexter , 
					    ETH-Z ,
					   Max-Planck-Gesellschaft (
					      
						
						  Synthetic ,
					      
					      
						
						Real ), 
						  HandNet ,
						
						FingerPaint 
					      
					  
				      
				    
				  
				  
				  
				    
					HANDS-2015 Workshop 
				      July
					  30th, 2014Posted
					  by James
				       
				      
					I'm organizing a workshop and
					challange associated with
					CVPR-2015. More information
					can be hound  here .
				      
				    
				    <
				  
				     3D
				    Hand Pose in Egocentric RGB+D
				     
				      Jan
				      5th, 2015Posted by James
				       
				      
					Hand pose estimation from an
					egocentric view using random
					cascades with synthetic depth
					data

					
					     G. Rogez, M. Khademi,
					    J. Supancic, J. Montiel,
					    D. Ramanan. "3D Hand
					    Pose Detection in
					    Egocentric RGB-D
					    Images"  Workshop
					    on Consumer Depth Cameras
					    for Computer Vision,
					    European Conference on
					    Computer Vision
					    (ECCV), Zurich,
					      Switzerland, Sept. 2014. PDF 
					    
					    
				    
				  

				      
					 
						 Self Paced Long Term Tracking 
						  April, 2013Posted by James
						 
						
						  Our paper, "Self Paced Learning for Long-Term Tracking" was accepted for publication at CVPR 2013. The paper presents a novel technique 
						  for adapting an appearance model for long term tracking. 
						    Project Source Code (Release Version, WIP)  
						       See it's README.txt for instructions.  Feel free to email me if you have problems. 
						      Self-paced learning for long-term tracking (Paper in PDF form)    Videos and Ground Truth (Data Set)   Output Tracks (CSV: x1, y1, x2, y2, cost). If x1 == NaN then the tracker said the target was occluded or out of frame.
						      Offline Output Tracks (CSV format)    Online Output Tracks  (CSV format)  

						    
						        J. Supancic, D. Ramanan. "Self-Paced Learning for Long-Term Tracking" Computer Vision and Pattern Recognition (CVPR), Portland, OR, June 2013.
						    
						  
						
					

					
						 Displaying Real Valued Data in OpenCV 
						Dec 19th, 2012Posted by James
						 
						
						  The imageeq function, which follows, equalizes a floating point image before displaying it. It is much better than MATLAB's imagesc for visualizing depth
						  data. 

void imageeq(const char* winName, cv::Mat_< float > im)
{
    // compute the order statistics
    vector< float > values;
    for(int rIter = 0; rIter < im.rows; rIter++)
        for(int cIter = 0; cIter < im.cols; cIter++)
                values.push_back(im.at< float >(rIter,cIter));
    std::sort(values.begin(),values.end());
    auto newEnd = std::unique(values.begin(),values.end());
    values.erase(newEnd,values.end());
    
    // compute an equalized image
    Mat showMe(im.rows,im.cols,DataType< uchar >::type);
    float oldQuant = 0;
    for(int qIter = 1; qIter (qIter)/256;
      
        float thresh_low = values[oldQuant*(values.size() - 1)];
        float thresh_high = values[quantile*(values.size() - 1)];
        //printf("q = %f low = %f high = %f\n",quantile,thresh_low,thresh_high);
        for(int rIter = 0; rIter < im.rows; rIter++)
            for(int cIter = 0; cIter < im.cols; cIter++)
            {
                float curValue = im.at< float >(rIter,cIter);
                if(curValue = thresh_low)
                    showMe.at< uchar >(rIter,cIter) = qIter-1;
            }
        
        oldQuant = quantile;
    }
    
    imshow(winName,showMe);
}

						
					

					
						 Welcome to my academic homepage 
						  Dec 18th, 2012Posted by James
						 
						
						  The above figure contains the  inverse HOG visualization  of the HOG features in a picture of me. I am a first year PhD student at UC Irvine. 
						  I work in computer vision. I'm interested in how we might exploit temporal data (tracking) and depth data (e.g. Kinect) in semi-supervised learning
						  to create effective detectors. 
						
					
				
				
				
					
							 James Steven Supančič III 
							 
							    
							   4209 Donald Bren Hall (Office) 
							   jsupanci at uci.edu 
							  
							  
							  PGP Key 
							  
							     github profile  
							   Links 							  
							 
							   
							  My Adviser,
							  Deva
							  Ramanan  
							   
							  My
							  Supervisor/Collaborator,
							  Gregory Rogez  
							    Computational Vision Group  
							    Department of Computer Science 
							    University of California at Irvine 
							
						
				
				
				 
			
		
	
	


	Copyright (c) 2012 James Supancic III. All rights reserved. Design by FCT.