Computational Vision | ICS | UC IrvineComputational Vision at UC Irvine  
  
  
    homeprojectspeoplepublicationsdatasetseventscoursescontactlinks
  

  
    Automatic Annotation of Everyday Movements
    Deva Ramanan, David Forsyth
    
      
      This paper describes a system that can annotate a video sequence with:
a description of the appearance of each actor; when the actor is in 
view; and a representation of the actor's activity while in view.  The 
system does not require a fixed background, and is automatic.  The 
system works by (1) tracking people in 2D and then, using an annotated motion capture dataset, (2) synthesizing an annotated 3D motion sequence matching the 2D tracks. The 3D motion capture data is manually annotated off-line using a class structure that describes everyday motions and allows motion annotations to be composed --- one may jump while running, for example. Descriptions computed from video of real motions show that the method is accurate. 


    
    
      Download: pdf
      Text Reference
Deva Ramanan and David A. Forsyth.
Automatic annotation of everyday movements.
In Sebastian Thrun, Lawrence Saul, and Bernhard {Sch\"{o}lkopf}, editors, Advances in Neural Information Processing Systems 16.
MIT Press, Cambridge, MA, 2004.
BibTeX Reference
@incollection{RamananF_NIPS_2003,
    author = "Ramanan, Deva and Forsyth, David A.",
    editor = {Thrun, Sebastian and Saul, Lawrence and {Sch\"{o}lkopf}, Bernhard},
    tag = "people",
    title = "Automatic Annotation of Everyday Movements",
    booktitle = "Advances in Neural Information Processing Systems 16",
    publisher = "MIT Press",
    address = "Cambridge, MA",
    year = "2004",
    keywords = "activity recognition, video annotation, single-camera tracking, dynamic Bayesian networks, motion capture"
}
    
  
  
    
      Computational Vision |
      School of Information and Computer Sciences |
      UC Irvine
    
    © 2007-2015 UC Irvine